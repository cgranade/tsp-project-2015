\documentclass[aps,pra,onecolumn,nofootinbib,superscriptaddress,tightenlines,
notitlepage,12pt]{revtex4-1}

%............................

\usepackage[ colorlinks = true,
             linkcolor = blue,
             urlcolor  = blue,
             citecolor = red,
             anchorcolor = green,
]{hyperref}

\usepackage[T1]{fontenc}

\usepackage{amsmath,amssymb,amsthm}

\newtheorem{conj}{Conjecture}

\newcommand{\tr}{\mathrm{tr}}

\begin{document}


\section{Numerically Testing a Conjecture}

\paragraph*{Supervision:} Marco Tomamichel

\paragraph*{Group size:} Variations of this problem are possible, for up to 3 students in total.

\paragraph*{Introduction:} In our daily work we often encounter certain inequalities that we\,---\,for one reason or another\,---\,believe to be true. 
%
As a trivial example we consider the inequality
\begin{align}
  \sqrt{a + b} \stackrel{?}{\leq} \sqrt{a} + \sqrt{b} \,, \label{eq:ex1}
\end{align}
and conjecture that it holds for all $a, b \geq 0$.
Now in this particular case it is in fact very easy to see that the relation always holds for positive $a$ and $b$. (To verify this, simply  square both sides of the inequality and note that $a + b \leq a + b + 2\sqrt{ab}$.) However, generally it is very difficult to asses if an inequality with several variables holds true for all allowed values of the variables by just staring at it. 

Obviously we could try to prove if it holds, using all the mathematical tools at our disposal. However, this might turn out to be very difficult and time consuming. And more often than not, \emph{Mathematica} cannot help us much either.
%
So the first step one often takes\,---\,to gauge if its worth investing further energy\,---\,is to numerically test the inequality. In the above case, one could for example pick values of $a$ and $b$ at random (according to some probability measure) and then simply evaluate the lefthand and righthand side of~\eqref{eq:ex1}. If the inequality holds for this random example we repeat the process for new random values, until we find a counterexample: a tuple $(a,b)$ that violates~\eqref{eq:ex1}. Well, for the above example we will obviously never find a counterexample, so we also have to abort at some point after we checked enough tuples and convinced ourselves that the inequality might actually hold.

\paragraph*{Goal:}
The goal of this project is to test some conjectured inequalities where the variables are density operators and quantum channels. These inequalities are currently the topic of intensive research and some of the best people in our field are trying to prove these conjectures analytically. However, surprisingly they have not been thoroughly tested using numerics, and this is where you can contribute. 

Using Python and QuTip, you will test the conjectures on randomly chosen states and channels (where applicable). You will optimize the code so that you can test it for larger systems. You will implement an algorithm to locally optimize your potential counterexample. You will write the code and document it in detail so that it can serve as a tutorial on how to use numerical methods to find counterexamples. The code and documentation will be an important part of your report.

\paragraph*{More background:}
The following inequalities will be considered:
\begin{description}
  \item[Petz Recovery Map and Relative Entropy]
    This conjecture is known to be false, because we have found numerical counterexamples. As a first step you should reproduce such counterexamples.
   \begin{align}
     I(A:B|C) \geq D \Big(\rho_{ABC} \Big\| (1_A \otimes \rho_{BC}^{\frac12})  (1_{AB} \otimes \rho_{C}^{-\frac12}) (\rho_{AC} \otimes 1_B) (1_{AB} \otimes \rho_{C}^{-\frac12} ) (1_A \otimes \rho_{BC}^{\frac12}) \Big)
   \end{align}
   Here $\rho_{ABC}$ is a quantum state on three systems. The quantity $I(A:B|C)$ is called the conditional mutual information and it is defined as
   \begin{align}
     I(A:B|C) = H(AC) + H(BC) - H(C) - H(ABC)
   \end{align}
   where $H(A) = -\tr (\rho_A \log \rho_A)$ is the von Neumann entropy of a state. Finally, the relative entropy is defined as $D(\rho\|\sigma) = \tr(\rho (\log \rho - \log \sigma))$.

  \item[Petz Recovery Map and Fidelity] This one might actually be true; indeed, we very much hope so. However, we cannot show this right now so the numerical tests will be very useful.
  \begin{align}
I(A:B|C) \geq -\log F \Big(\rho_{ABC} , (1_A \otimes \rho_{BC}^{\frac12})  (1_{AB} \otimes \rho_{C}^{-\frac12}) (\rho_{AC} \otimes 1_B) (1_{AB} \otimes \rho_{C}^{-\frac12} ) (1_A \otimes \rho_{BC}^{\frac12}) \Big)
  \end{align}
     
\end{description}

There are further variations of this inequality available that require picking two states and a quantum channel at random, but we will get to that later. 

\section{Entropy of Informative Priors for State and Channel Tomography}

\paragraph*{Supervision:} Chris Granade

\paragraph*{Group size:} Up to two students would be ideal for this project.

\paragraph*{Introduction:} Bayesian inference is a very useful tool in a wide range of fields, including quantum information. In particular, Bayes' rule tells us how to describe what we learn from experimental data,
\begin{equation}\label{bayes}
  \Pr(\text{model} | \text{data}) = \frac{\Pr(\text{data} | \text{model})}{\Pr(\text{data})} \Pr(\text{model}).
\end{equation}
Here, $\Pr(\text{data} | \text{model})$ is the \emph{likelihood function} for
a particular experiment--- for instance, Born's Rule, $\tr(E \rho)$. In that
case, we think of the mixed state $\rho$ as a model we would like to learn;
this problem is called \emph{tomography}. The distribution $\Pr(\text{model} |
\text{data})$ encodes the probability for different models conditioned on the
experimental data we collect. This distribution is called the
\emph{posterior}, and can be used to estimate models, characterize our
uncertainty and to design new experiments to learn adaptively. Though the
normalization factor $\Pr(\text{data})$ encodes useful information about the
plausibility of our model, we will not concern ourselves with it at the moment.

Finally, the distribution $\Pr(\text{model})$ is called the \emph{prior} and
is how we account for the assumptions we make before we see any data. There is
a wide range of work concerning how to best choose priors, and in particular,
how constraints imposed by \emph{a priori} assumptions should be represented.
One very important principle that is often employed in choosing priors is that
they should represent as little information as is possible while still encoding
particular assumptions. This is formalized as the \emph{maximum entropy} principle,
which prescribes that one should choose a prior that maximizes the
differential entropy
\begin{equation}
    H(\Pr(x)) = -\int p(x) \log p(x) \mathrm{d}x,
\end{equation}
where for brevity we have let $x$ stand for an arbitrary model.
For example, the normal distribution is the maximum entropy prior that arises
from constraining the mean and variance\footnote{Wikipedia has a nice derivation
of this fact, if you are interested. See \url{https://goo.gl/Ib1LbK}.}.

For quantum states, picking useful priors can be a bit tricky. In order to
perform Bayesian state tomography, we'd like to be able to encode into our
prior assumptions about which state we think we probably have, such that when
repeating similar experiments, we don't need as much data. Recently, Granade,
Combes and Cory have proposed a new prior that does this known as the
generalized amplitude damping (GAD) prior. They have conjectured that this
prior is also a maximum entropy prior, subject to the constraints we would
like to impose. In this project, you will numerically test whether the GAD
prior is maximum entropy under these constraints by calculating the entropy of
both the GAD prior and minor variations on that prior. In doing so, you will
either provide evidence for or counterexamples against the validity of that
maximum-entropy conjecture for GAD priors.


\section{Least favorable priors for quantum states}

\paragraph*{Supervision:} Chris Ferrie

\paragraph*{Group size:} Suitable for one student.

\paragraph*{Introduction:} Another possible prescription for a prior comes from decision theory and \emph{worst case} analysis.  To specifying this one, we need to know a little decision theory first.  Recall, when the fidelity between the ``true'' state $\rho$ and your estimated state $\sigma$ is near one, $F(\rho,\sigma) \approx 1$, you've done a good job estimating the state.  In the Bayesian approach, we have at all times a distribution $\Pr(\rho|\texttt{data})$ which encodes our knowledge of the state.  Thus, the best we can do is choose $\sigma$ to be the state that solves
\begin{equation}
	\int F(\rho,\sigma) \Pr(\rho|\texttt{data}) d\rho = \max_{\sigma'}	\int F(\rho,\sigma') \Pr(\rho|\texttt{data}) d\rho.
\end{equation}

Your knowledge after a bunch of measurements is $\Pr(\rho|\texttt{data})$.  According to Equation \eqref{bayes} above, this requires a \emph{prior} $\pi(\rho):=\Pr(\rho)$, which is what you know before seeing any data.  Now, what if $\rho$ is selected by an adversary?  Or, your funding agency doesn't want your analysis to hinge on what you, personally, know?  In this case, the state you want to estimate is the $\sigma$ which solves (using Bayes rule above)
\begin{equation}
\min_\pi	\int F(\rho,\sigma) \frac{\Pr(\texttt{data}|\rho)\pi(\rho)}{\Pr(\texttt{data})} d\rho = \min_\pi \max_{\sigma'}	\int F(\rho,\sigma')  \frac{\Pr(\texttt{data}|\rho)\pi(\rho)}{\Pr(\texttt{data})} d\rho.
\end{equation}

Now, these look like nasty integrals.  Lucky, we have the tools to numerically calculate them with Monte Carlo algorithms.  Your task will be to implement numerical optimization routines which approximate the solution to these problems.  With the solution in hand, we will analyze its characteristics in hopes of gleaning new insights into the problem of quantum state estimation.



\section{Adaptive measurement tomography}

\paragraph*{Supervision:} Chris Ferrie

\paragraph*{Group size:} Suitable for one student.

\paragraph*{Introduction:} Once prior is chosen (see above), one must actually perform measurements, gather and process data to arrive a tomographic estimate of the density matrix representing the preparation of the quantum system.  One can write a horribly complicated global optimization problem which encodes the solution to the \emph{best} set of measurements to perform conditional on all past and potentially future data.  This is completely intractable even numerically, so we heuristics which can perform \emph{well enough}.  

You will simulate quantum tomography experiments and test heuristics for adaptive estimation of not only quantum density matrices, but \emph{regions} of density matrices.  If numerical evidence suggests that your heuristic scales in the same way we know the optimal solution must (from known asymptotic lower bounds), you will have a found a practical prescription for experimentalists to perform the estimation of quantum states.


\bibliography{library}

\end{document}
